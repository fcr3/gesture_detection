{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from openvino.inference_engine import IENetwork\n",
    "from openvino.inference_engine import IEPlugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods for object detection\n",
    "\n",
    "def setup_obj_net(precision, device_choice):\n",
    "    # path_to_objxml = './gesture_ssd_fp16/frozen_inference_graph.xml'\n",
    "    # path_to_objbin = './gesture_ssd_fp16/frozen_inference_graph.bin'\n",
    "    \n",
    "    path_to_objxml = './gesture_folders/test_fp16/frozen_inference_graph.xml'\n",
    "    path_to_objbin = './gesture_folders/test_fp16/frozen_inference_graph.bin'\n",
    "    \n",
    "    if precision.lower() == 'fp32':\n",
    "        # path_to_objxml = './gesture_ssd/frozen_inference_graph.xml'\n",
    "        # path_to_objbin = './gesture_ssd/frozen_inference_graph.bin'\n",
    "    \n",
    "        path_to_objxml = './test_fp32/frozen_inference_graph.xml'\n",
    "        path_to_objbin = './test_fp32/frozen_inference_graph.bin'\n",
    "    else:\n",
    "        print('lower precision')\n",
    "\n",
    "    net = IENetwork(model=path_to_objxml, weights=path_to_objbin)\n",
    "    input_layer = next(iter(net.inputs))\n",
    "    output_layer = next(iter(net.outputs))\n",
    "    input_shape = net.inputs[input_layer].shape\n",
    "    \n",
    "    obj_plugin = IEPlugin(device=device_choice)\n",
    "    if device_choice.lower() == 'cpu':\n",
    "        ext = '/opt/intel/openvino/deployment_tools/inference_engine/'\n",
    "        ext = ext + 'lib/intel64/libcpu_extension_avx2.so'\n",
    "        obj_plugin.add_cpu_extension(ext)\n",
    "    obj_exec_net = obj_plugin.load(network=net, num_requests=1)\n",
    "    \n",
    "    return {\n",
    "        'net': obj_exec_net, \n",
    "        'input_layer': input_layer,\n",
    "        'output_layer': output_layer,\n",
    "        'input_shape': input_shape\n",
    "    }\n",
    "\n",
    "def pre_obj_processing(obj_frame, input_shape):\n",
    "    n, c, h, w = input_shape\n",
    "    obj_in_frame = cv2.resize(obj_frame, (w, h))\n",
    "    obj_in_frame = obj_in_frame.transpose((2, 0, 1))\n",
    "    obj_in_frame = obj_in_frame.reshape((n, c, h, w))\n",
    "    \n",
    "    return {\n",
    "        'blob' : obj_in_frame, \n",
    "        'frame': obj_frame, \n",
    "    }\n",
    "\n",
    "def draw_bb(obj_det, frame):\n",
    "    i_w = frame.shape[1]\n",
    "    i_h = frame.shape[0]\n",
    "    drawn = False\n",
    "    \n",
    "    proposals = []\n",
    "    \n",
    "    for obj in obj_det[0][0]:\n",
    "        if obj[2] > 0.5:\n",
    "            proposals.append(obj)\n",
    "    if len(proposals) == 0:\n",
    "        return {'status': False, 'miniframe': None, 'frame': frame, 'class': 8, 'offset': None}\n",
    "    \n",
    "    proposed_obj = max(proposals, key=lambda x: x[2])\n",
    "    xmin = int(proposed_obj[3] * i_w)\n",
    "    ymin = int(proposed_obj[4] * i_h)\n",
    "    xmax = int(proposed_obj[5] * i_w)\n",
    "    ymax = int(proposed_obj[6] * i_h)\n",
    "    class_id = int(proposed_obj[1])\n",
    "    green = (0, 255, 0)\n",
    "    cv2.putText(frame, str(class_id), (xmin, ymin), cv2.FONT_HERSHEY_SIMPLEX, 0.8, green, 2, cv2.LINE_AA )\n",
    "    cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), green, 2)\n",
    "    \n",
    "    xmid = (xmin + xmax) / 2\n",
    "    ymid = (ymin + ymax) / 2\n",
    "    \n",
    "    xmin = int(xmid - 149)\n",
    "    xmax = int(xmid + 150)\n",
    "    ymin = int(ymid - 149)\n",
    "    ymax = int(ymid + 150)\n",
    "    \n",
    "    if ymin >= i_h or xmin >= i_w or ymin < 0 or xmin < 0:\n",
    "        return {'status': False, 'miniframe': None, 'frame': frame, 'class': 8, 'offset': None}\n",
    "    \n",
    "    # Draw box and label\\class_id\n",
    "    cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (255, 255, 255), 2)\n",
    "    \n",
    "    return {'status': True, 'miniframe': frame[ymin:ymax, xmin:xmax], \n",
    "            'frame': frame, 'class': class_id, 'offset': (xmin, ymin)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obj Detection Demo\n",
    "def main():\n",
    "    # object detection net\n",
    "    net_dict = setup_obj_net('fp16', 'MYRIAD')\n",
    "    obj_exec_net = net_dict['net']\n",
    "    input_shape = net_dict['input_shape']\n",
    "    input_layer = net_dict['input_layer']\n",
    "    output_layer = net_dict['output_layer']\n",
    "    \n",
    "    vs = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        ret, vframe = vs.read()\n",
    "        image_dict = pre_obj_processing(vframe, input_shape)\n",
    "        inpBlob = image_dict['blob']\n",
    "\n",
    "        obj_res = obj_exec_net.infer({'image_tensor': inpBlob})\n",
    "        obj_det = obj_res['DetectionOutput']\n",
    "        \n",
    "        draw_bb(obj_det, image_dict['frame'])\n",
    "        cv2.imshow(\"Frame\", image_dict['frame'])\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    " \n",
    "    # do a bit of cleanup\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
